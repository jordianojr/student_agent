text
Auto Scaling in AWS dynamically adjusts the number of instances in an Auto Scaling group based on metrics like CPU usage, ensuring resources align with workload demand.. Auto Scaling scales the assigned Auto Scaling group out and adds another instance. When the CPU use becomes greater than 60%, the desired capacity becomes four, or 2x2. If the CPU use is between 60%-80%, the desired capacity of the group increases by 1 instance to 11 instances. When the usage spike subsides and average CPU use drops to 20%-40%, the desired capacity of the group decreases by 1 instance to 11 instances. If the CPU use continues to rise and becomes to more than 80%, the second step adjustments would be triggered, and an additional server would be launched.
CloudWatch alarms monitor metrics (e.g., latency, CPU usage) and trigger Auto Scaling policies to scale out (add instances) or scale in (remove instances) when thresholds are breached.. • In this scenario, a CloudWatch alarm is assigned to the load balancer that keeps track of latency. When it is triggered, the alarm notifies Amazon CloudWatch. This triggers CloudWatch to execute an Auto Scaling policy. When you create a step scaling policy, you add one or more step adjustments that enable you to scale resources based on the size of the alarm breach. Auto Scaling scales the assigned Auto Scaling group out and adds another instance.
Step scaling policies define ranges for metrics (e.g., CPU usage between 60%-80%) and specify scaling adjustments (e.g., adding 1 instance) for each range, avoiding overlapping or gaps in thresholds..  When you create a step scaling policy, you add one or more step adjustments that enable you to scale resources based on the size of the alarm breach. Each step adjustment specifies a lower bound for the metric value, an upper bound for the metric value, and the amount by which to scale, based on the scaling adjustment type. The ranges of your step adjustments can't overlap or have a gap. If the CPU use is between 60%-80%, the desired capacity of the group increases by 1 instance to 11 instances. This change is based on the second step adjustment of the scale-out policy, which will add 1 instance when the average CPU use is between 60%-80%.
Warm-up periods are required for newly launched instances to ensure they are fully operational before contributing to aggregated metrics, preventing premature scaling decisions.. The new instance is launched, but not added, to the aggregated group metrics until after a warm-up period expires. While scaling out, we do not consider instances that are warming up as part of the current capacity of the group. Therefore, multiple alarm breaches that fall in the range of the same step adjustment result in a single scaling activity. After entering the warmup period from the second step adjustment, the second instance is added to the Auto Scaling group.
Minimum capacity in an Auto Scaling group is the lowest number of instances that can run, while desired capacity is the default number, and maximum capacity is a hard limit on scaling.. The desired capacity is different from the minimum capacity. The desired capacity of an Auto Scaling group is the default number of instances that should be running. The minimum capacity of a group is the fewest number of instances the group can have running. Set the minimum and maximum capacity parameter values carefully. The desired capacity is different from the minimum capacity. The next time the alarm gets triggered, you can no longer double the current group capacity because the maximum capacity is set to 12.
Scaling in should be done slowly to avoid workload spikes that could cause thrashing, while scaling out should be done quickly to handle sudden traffic increases.. Be sure to scale back very slowly, because you do not want to create something that causes CPU thrashing. It would be possible to set up a step adjustment to scale in more aggressively if the load continues to drop. Just remember that it is better to scale up quickly and scale down slowly. If you terminate an instance too quickly, another spike might take place and cause more servers to be created. scaling out early, and scale in slowly, rather than aggressively.
Lifecycle hooks allow custom actions (e.g., data cleanup) to be executed when instances are launched or terminated, ensuring smooth application of scaling events.. Use lifecycle hooks to perform custom actions when Auto Scaling launches or terminates instances. An example of a lifecycle hook would be when someone uploads something to your Amazon S3 bucket.
Stateful applications require careful configuration of Auto Scaling groups, as instances may need time to stabilize and become fully usable after launch.. Stateful applications require additional automatic configuration of instances that are launched into Auto Scaling groups. Remember that instances can take several minutes after launch before they are fully usable.
Auto Scaling interacts with Elastic Load Balancing to manage instance termination, using connection draining to ensure active connections are closed before an instance is removed.. Elastic Load Balancing has a feature called connection draining. This feature is a period of time when Elastic Load Balancing stops sending requests to the instance that was identified for termination prior to deregistering it . After the time has elapsed, Elastic Load Balancing will forcefully close all open connections and terminate the targeted instance.
"Maximum capacity is determined by application needs, budgets, or infrastructure constraints, balancing resource efficiency with system stability.. Selecting a reasonable maximum capacity size depends on your application and possibly a budget. You pay for what you use; therefore, your organization might limit you from running more than a certain number of instances. Even if you don’t have a budget restriction, there is no single answer. Be sure to scale back very slowly, because you do not want to create something that causes CPU thrashing."
Step adjustments in scaling policies must adhere to strict rules (e.g., no overlapping ranges, one null bound per direction) to ensure predictable and reliable scaling behavior..  There are a few rules for the step adjustments for your policy: • The ranges of your step adjustments can't overlap or have a gap. • Only one step adjustment can have a null lower bound, or negative infinity. If one step adjustment has a negative lower bound, then there must be a step adjustment with a null lower bound. • Only one step adjustment can have a null upper bound, or positive infinity. If one step adjustment has a positive upper bound, then there must be a step adjustment with a null upper bound. • The upper and lower bound can't be null in the same step adjustment.
"Scaling policies avoid cooldown periods, but step adjustments can be configured to scale in more aggressively when load drops, though this must be balanced with potential spikes.. Auto Scaling step adjustments do not support the use of ""cooldown periods"". It would be possible to set up a step adjustment to scale in more aggressively if the load continues to drop. Be sure to scale back very slowly, because you do not want to create something that causes CPU thrashing. Scaling in means that you decrease the computing capacity due to low use."
Minimum capacity should consider instance launch times (minutes) and workload unpredictability, avoiding zero minimum for applications with sporadic demand.. Deciding on the minimum capacity size depends on the type of applications that you run. Here are some things to consider: If you are processing batches that run once a week, you might want to set the minimum to zero. Remember that it takes minutes to launch a new instance, depending on the complexity of your launch configuration. You might not be able to afford zero minimum capacity to start with. Remember that it takes minutes to launch a new instance, depending on the complexity of your launch configuration. You might not be able to afford zero minimum capacity to start with.
Auto Scaling groups aim to maintain desired capacity, but warm-up periods and instance readiness can temporarily delay changes in aggregated metrics.. The new instance is launched, but not added, to the aggregated group metrics until after a warm-up period expires. While scaling out, we do not consider instances that are warming up as part of the current capacity of the group. After entering the warmup period from the second step adjustment, the second instance is added to the Auto Scaling group.
The relationship between minimum capacity and Availability Zones ensures high availability, with at least one instance per zone for redundancy.. If you require at least one instance per Availability Zone to start with, the minimum capacity size should be set to the number of Availability Zones. The case on this slide requires a minimum of two instances across two separate Availability Zones, so the desired capacity is two.
Step scaling policies can scale out incrementally (e.g., +1 instance for CPU 60%-80%) and scale in progressively (e.g., -1 instance for CPU 20%-40%) to stabilize workload..  If the CPU use is between 60%-80%, the desired capacity of the group increases by 1 instance to 11 instances. When the usage spike subsides and average CPU use drops to 20%-40%, the desired capacity of the group decreases by 1 instance to 11 instances. This change is based on the third step adjustment of the policy, which removes 1 instance when the average CPU use is 20%-40%.
Auto Scaling balances cost efficiency and system stability by dynamically adjusting resources, avoiding over-provisioning while ensuring capacity to handle traffic spikes.. You pay for what you use, so you don’t need to launch more instances than you need, and your resources can automatically scale based on demand. Auto Scaling balances cost efficiency and system stability by dynamically adjusting resources, avoiding over-provisioning while ensuring capacity to handle traffic spikes. Be sure to scale back very slowly, because you do not want to create something that causes CPU thrashing.
